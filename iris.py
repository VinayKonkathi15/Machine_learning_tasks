# -*- coding: utf-8 -*-
"""Iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qly1yndO_FXYs4_PpXXoWi4cWl5VFA0v
"""

# Importing necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

print("Iris dataset loaded successfully.")

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print("Dataset split into training and testing sets.")
print("Training set size:", len(X_train))
print("Testing set size:", len(X_test))

# Standardize features by removing the mean and scaling to unit variance
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Features standardized successfully.")

#Initialize and train the Support Vector Classifier (SVC) model
svc_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)
svc_model.fit(X_train_scaled, y_train)

print("Support Vector Classifier (SVC) model trained successfully.")

# Make predictions on the testing set using SVC
y_pred_svc = svc_model.predict(X_test_scaled)

# Evaluate the SVC model
accuracy_svc = accuracy_score(y_test, y_pred_svc)
print("Support Vector Classifier (SVC) Model Accuracy:", accuracy_svc)
print("\nClassification Report for SVC:")
print(classification_report(y_test, y_pred_svc, target_names=iris.target_names))

# Plot confusion matrix for SVC
cm_svc = confusion_matrix(y_test, y_pred_svc)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_svc, annot=True, cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for SVC')
plt.show()

# Initialize and train the k-Nearest Neighbors (kNN) model
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled, y_train)

print("k-Nearest Neighbors (kNN) model trained successfully.\n")

# Make predictions on the testing set using kNN
y_pred_knn = knn_model.predict(X_test_scaled)

print("Predictions made using kNN model.")

# Evaluate the kNN model
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("\n\nk-Nearest Neighbors (kNN) Model Accuracy:", accuracy_knn)
print("\nClassification Report for kNN:")
print(classification_report(y_test, y_pred_knn, target_names=iris.target_names))

# Section 12: Plot decision boundaries for kNN with actual class labels as markers
# Define meshgrid with all 4 features
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 0.1))

# Generate meshgrid with all 4 features for prediction
xx_pred = np.c_[xx.ravel(), yy.ravel(), np.zeros_like(xx.ravel()), np.zeros_like(xx.ravel())]

# Predict using kNN model
Z = knn_model.predict(xx_pred)
Z = Z.reshape(xx.shape)

plt.figure(figsize=(8, 6))
plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)

# Plot actual data points with different markers for each class
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, s=50, edgecolors='k', marker='o', label='Actual Class')

plt.title('Decision Boundaries for kNN with Actual Class Labels')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.legend()
plt.show()